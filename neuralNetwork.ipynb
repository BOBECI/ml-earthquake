{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedFeatureCorr = pd.read_csv(\"dataset/corr.csv\")\n",
    "data = pd.read_csv(\"dataset/preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_feature_count =           22\n",
    "last_feature_count =            21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sortedFeatureCorr.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(first_feature_count , sortedFeatureCorr.shape[0] - last_feature_count):\n",
    "    data = data.drop(a[i], axis=1)\n",
    "data=data.drop(list(data.columns)[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[     1      2      3      4      5]\n",
      " [ 78815  87257 136412 183844 275766]]\n"
     ]
    }
   ],
   "source": [
    "data_npWNan = data.iloc[:, :].values\n",
    "\n",
    "data_np = data_npWNan[data_npWNan[:,-1]!= -1 ]\n",
    "unique_elements, counts_elements = np.unique(data_np[:,-1], return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = data_np[:, :-1]\n",
    "# target = data_np[:, -1].reshape(data_np.shape[0], 1)\n",
    "target = data_np[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9339, 1.7468, 1.1173, 0.8291, 0.5527], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', np.unique(target), target)\n",
    "class_weights = torch.from_numpy(class_weights)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainAndVal, X_test, y_trainAndVal, y_test = train_test_split(feature, target, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_trainAndVal, y_trainAndVal, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_val = sc.transform(X_val)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "epochs = 50\n",
    "input_dim = first_feature_count + last_feature_count - 1\n",
    "output_dim = 5\n",
    "lr_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class datasetLoad(Dataset):\n",
    "    def __init__(self, features,labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = datasetLoad(X_train, y_train)\n",
    "X_val = datasetLoad(X_val, y_val)\n",
    "X_test = datasetLoad(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = X_train, batch_size = batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset = X_val, batch_size = batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = X_test, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class neuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden1_dim, hidden2_dim, output_dim):\n",
    "        super(neuralNetwork, self).__init__()\n",
    "        \n",
    "        self.hidden1 = nn.Linear(input_dim, hidden1_dim)\n",
    "        self.bnhidden1 = nn.BatchNorm1d(hidden1_dim)\n",
    "        \n",
    "        self.hidden2 = nn.Linear(hidden1_dim, hidden2_dim)\n",
    "        self.bnhidden2 = nn.BatchNorm1d(hidden2_dim)\n",
    "        \n",
    "        self.output = nn.Linear(hidden2_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.hidden1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.elu_(x, alpha=1.) \n",
    "        x = F.leaky_relu_(self.bnhidden1(x), negative_slope=0.01)\n",
    "    \n",
    "        x = self.hidden2(x)\n",
    "        x = F.leaky_relu_(self.bnhidden2(x), negative_slope=0.01)\n",
    "        \n",
    "        \n",
    "        \n",
    "        outputs = self.output(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neuralNetwork(input_dim, 20,20, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd ya da adam kullanilabilir\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "\n",
    "# learning rate'in 20 ve 40. epochta 10da 1'ine dusmesini sagladim\n",
    "scheduler = MultiStepLR(optimizer, milestones=[5,10,20,40], gamma=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Iteration: 0. Loss: 1.6847076416015625. Accuracy: 18.\n",
      "Epoch: 0. Iteration: 243. Loss: 1.3781368732452393. Accuracy: 39.\n",
      "Epoch: 0. Iteration: 486. Loss: 1.370155692100525. Accuracy: 40.\n",
      "Epoch: 0. Iteration: 729. Loss: 1.3735897541046143. Accuracy: 40.\n",
      "Epoch: 0. Iteration: 972. Loss: 1.357505202293396. Accuracy: 40.\n",
      "Epoch: 1. Iteration: 0. Loss: 1.3236922025680542. Accuracy: 41.\n",
      "Epoch: 1. Iteration: 243. Loss: 1.3903530836105347. Accuracy: 41.\n",
      "Epoch: 1. Iteration: 486. Loss: 1.3614193201065063. Accuracy: 40.\n",
      "Epoch: 1. Iteration: 729. Loss: 1.3563145399093628. Accuracy: 40.\n",
      "Epoch: 1. Iteration: 972. Loss: 1.3353302478790283. Accuracy: 40.\n",
      "Epoch: 2. Iteration: 0. Loss: 1.3200013637542725. Accuracy: 39.\n",
      "Epoch: 2. Iteration: 243. Loss: 1.3373721837997437. Accuracy: 41.\n",
      "Epoch: 2. Iteration: 486. Loss: 1.3484879732131958. Accuracy: 40.\n",
      "Epoch: 2. Iteration: 729. Loss: 1.3249375820159912. Accuracy: 40.\n",
      "Epoch: 2. Iteration: 972. Loss: 1.333161473274231. Accuracy: 40.\n",
      "Epoch: 3. Iteration: 0. Loss: 1.3414973020553589. Accuracy: 40.\n",
      "Epoch: 3. Iteration: 243. Loss: 1.360468864440918. Accuracy: 41.\n",
      "Epoch: 3. Iteration: 486. Loss: 1.344218134880066. Accuracy: 40.\n",
      "Epoch: 3. Iteration: 729. Loss: 1.3125914335250854. Accuracy: 41.\n",
      "Epoch: 3. Iteration: 972. Loss: 1.3052279949188232. Accuracy: 41.\n",
      "Epoch: 4. Iteration: 0. Loss: 1.387237548828125. Accuracy: 40.\n",
      "Epoch: 4. Iteration: 243. Loss: 1.3154875040054321. Accuracy: 40.\n",
      "Epoch: 4. Iteration: 486. Loss: 1.337427020072937. Accuracy: 40.\n",
      "Epoch: 4. Iteration: 729. Loss: 1.3068857192993164. Accuracy: 41.\n",
      "Epoch: 4. Iteration: 972. Loss: 1.286884069442749. Accuracy: 40.\n",
      "Epoch: 5. Iteration: 0. Loss: 1.3866965770721436. Accuracy: 40.\n",
      "Epoch: 5. Iteration: 243. Loss: 1.2768138647079468. Accuracy: 40.\n",
      "Epoch: 5. Iteration: 486. Loss: 1.3386365175247192. Accuracy: 40.\n",
      "Epoch: 5. Iteration: 729. Loss: 1.3750693798065186. Accuracy: 40.\n",
      "Epoch: 5. Iteration: 972. Loss: 1.37880539894104. Accuracy: 41.\n",
      "Epoch: 6. Iteration: 0. Loss: 1.3384827375411987. Accuracy: 41.\n",
      "Epoch: 6. Iteration: 243. Loss: 1.3466445207595825. Accuracy: 40.\n",
      "Epoch: 6. Iteration: 486. Loss: 1.3516762256622314. Accuracy: 40.\n",
      "Epoch: 6. Iteration: 729. Loss: 1.3129481077194214. Accuracy: 40.\n",
      "Epoch: 6. Iteration: 972. Loss: 1.3525605201721191. Accuracy: 40.\n",
      "Epoch: 7. Iteration: 0. Loss: 1.3234103918075562. Accuracy: 40.\n",
      "Epoch: 7. Iteration: 243. Loss: 1.3393681049346924. Accuracy: 42.\n",
      "Epoch: 7. Iteration: 486. Loss: 1.2933990955352783. Accuracy: 40.\n",
      "Epoch: 7. Iteration: 729. Loss: 1.329856038093567. Accuracy: 40.\n",
      "Epoch: 7. Iteration: 972. Loss: 1.4158552885055542. Accuracy: 42.\n",
      "Epoch: 8. Iteration: 0. Loss: 1.3299667835235596. Accuracy: 41.\n",
      "Epoch: 8. Iteration: 243. Loss: 1.33302640914917. Accuracy: 41.\n",
      "Epoch: 8. Iteration: 486. Loss: 1.3030856847763062. Accuracy: 41.\n",
      "Epoch: 8. Iteration: 729. Loss: 1.3562062978744507. Accuracy: 41.\n",
      "Epoch: 8. Iteration: 972. Loss: 1.3465501070022583. Accuracy: 40.\n",
      "Epoch: 9. Iteration: 0. Loss: 1.3428107500076294. Accuracy: 40.\n",
      "Epoch: 9. Iteration: 243. Loss: 1.3695061206817627. Accuracy: 41.\n",
      "Epoch: 9. Iteration: 486. Loss: 1.3125337362289429. Accuracy: 40.\n",
      "Epoch: 9. Iteration: 729. Loss: 1.3289210796356201. Accuracy: 41.\n",
      "Epoch: 9. Iteration: 972. Loss: 1.3182373046875. Accuracy: 41.\n",
      "Epoch: 10. Iteration: 0. Loss: 1.3397237062454224. Accuracy: 41.\n",
      "Epoch: 10. Iteration: 243. Loss: 1.3456199169158936. Accuracy: 41.\n",
      "Epoch: 10. Iteration: 486. Loss: 1.3806601762771606. Accuracy: 40.\n",
      "Epoch: 10. Iteration: 729. Loss: 1.3610793352127075. Accuracy: 40.\n",
      "Epoch: 10. Iteration: 972. Loss: 1.377333641052246. Accuracy: 40.\n",
      "Epoch: 11. Iteration: 0. Loss: 1.4938277006149292. Accuracy: 41.\n",
      "Epoch: 11. Iteration: 243. Loss: 1.3345699310302734. Accuracy: 41.\n",
      "Epoch: 11. Iteration: 486. Loss: 1.3700474500656128. Accuracy: 41.\n",
      "Epoch: 11. Iteration: 729. Loss: 1.3383375406265259. Accuracy: 41.\n",
      "Epoch: 11. Iteration: 972. Loss: 1.278586745262146. Accuracy: 41.\n",
      "Epoch: 12. Iteration: 0. Loss: 1.2739003896713257. Accuracy: 41.\n",
      "Epoch: 12. Iteration: 243. Loss: 1.4051570892333984. Accuracy: 41.\n",
      "Epoch: 12. Iteration: 486. Loss: 1.368876338005066. Accuracy: 40.\n",
      "Epoch: 12. Iteration: 729. Loss: 1.3437285423278809. Accuracy: 41.\n",
      "Epoch: 12. Iteration: 972. Loss: 1.333821177482605. Accuracy: 42.\n",
      "Epoch: 13. Iteration: 0. Loss: 1.3148781061172485. Accuracy: 41.\n",
      "Epoch: 13. Iteration: 243. Loss: 1.3902734518051147. Accuracy: 39.\n",
      "Epoch: 13. Iteration: 486. Loss: 1.3652077913284302. Accuracy: 41.\n",
      "Epoch: 13. Iteration: 729. Loss: 1.3358471393585205. Accuracy: 40.\n",
      "Epoch: 13. Iteration: 972. Loss: 1.307504415512085. Accuracy: 41.\n",
      "Epoch: 14. Iteration: 0. Loss: 1.3640481233596802. Accuracy: 41.\n",
      "Epoch: 14. Iteration: 243. Loss: 1.3326623439788818. Accuracy: 41.\n",
      "Epoch: 14. Iteration: 486. Loss: 1.3606414794921875. Accuracy: 41.\n",
      "Epoch: 14. Iteration: 729. Loss: 1.3091388940811157. Accuracy: 41.\n",
      "Epoch: 14. Iteration: 972. Loss: 1.393673062324524. Accuracy: 39.\n",
      "Epoch: 15. Iteration: 0. Loss: 1.3254586458206177. Accuracy: 39.\n",
      "Epoch: 15. Iteration: 243. Loss: 1.295819640159607. Accuracy: 41.\n",
      "Epoch: 15. Iteration: 486. Loss: 1.3151872158050537. Accuracy: 41.\n",
      "Epoch: 15. Iteration: 729. Loss: 1.354828953742981. Accuracy: 41.\n",
      "Epoch: 15. Iteration: 972. Loss: 1.3701716661453247. Accuracy: 40.\n",
      "Epoch: 16. Iteration: 0. Loss: 1.3623263835906982. Accuracy: 41.\n",
      "Epoch: 16. Iteration: 243. Loss: 1.3445518016815186. Accuracy: 39.\n",
      "Epoch: 16. Iteration: 486. Loss: 1.30254328250885. Accuracy: 40.\n",
      "Epoch: 16. Iteration: 729. Loss: 1.3438661098480225. Accuracy: 41.\n",
      "Epoch: 16. Iteration: 972. Loss: 1.3842777013778687. Accuracy: 40.\n",
      "Epoch: 17. Iteration: 0. Loss: 1.369188666343689. Accuracy: 40.\n",
      "Epoch: 17. Iteration: 243. Loss: 1.4366718530654907. Accuracy: 41.\n",
      "Epoch: 17. Iteration: 486. Loss: 1.3307220935821533. Accuracy: 41.\n",
      "Epoch: 17. Iteration: 729. Loss: 1.3556721210479736. Accuracy: 41.\n",
      "Epoch: 17. Iteration: 972. Loss: 1.3406699895858765. Accuracy: 41.\n",
      "Epoch: 18. Iteration: 0. Loss: 1.4009759426116943. Accuracy: 41.\n",
      "Epoch: 18. Iteration: 243. Loss: 1.3230395317077637. Accuracy: 41.\n",
      "Epoch: 18. Iteration: 486. Loss: 1.3207257986068726. Accuracy: 40.\n",
      "Epoch: 18. Iteration: 729. Loss: 1.29764723777771. Accuracy: 41.\n",
      "Epoch: 18. Iteration: 972. Loss: 1.365531325340271. Accuracy: 41.\n",
      "Epoch: 19. Iteration: 0. Loss: 1.3467786312103271. Accuracy: 41.\n",
      "Epoch: 19. Iteration: 243. Loss: 1.3390218019485474. Accuracy: 41.\n",
      "Epoch: 19. Iteration: 486. Loss: 1.3417938947677612. Accuracy: 41.\n",
      "Epoch: 19. Iteration: 729. Loss: 1.390593409538269. Accuracy: 41.\n",
      "Epoch: 19. Iteration: 972. Loss: 1.3519726991653442. Accuracy: 41.\n",
      "Epoch: 20. Iteration: 0. Loss: 1.3617140054702759. Accuracy: 41.\n",
      "Epoch: 20. Iteration: 243. Loss: 1.3412951231002808. Accuracy: 41.\n",
      "Epoch: 20. Iteration: 486. Loss: 1.3251917362213135. Accuracy: 40.\n",
      "Epoch: 20. Iteration: 729. Loss: 1.3467859029769897. Accuracy: 41.\n",
      "Epoch: 20. Iteration: 972. Loss: 1.325040340423584. Accuracy: 40.\n",
      "Epoch: 21. Iteration: 0. Loss: 1.3055685758590698. Accuracy: 40.\n",
      "Epoch: 21. Iteration: 243. Loss: 1.3866987228393555. Accuracy: 41.\n",
      "Epoch: 21. Iteration: 486. Loss: 1.3019788265228271. Accuracy: 40.\n",
      "Epoch: 21. Iteration: 729. Loss: 1.3577736616134644. Accuracy: 40.\n",
      "Epoch: 21. Iteration: 972. Loss: 1.2957707643508911. Accuracy: 41.\n",
      "Epoch: 22. Iteration: 0. Loss: 1.3240303993225098. Accuracy: 42.\n",
      "Epoch: 22. Iteration: 243. Loss: 1.3258718252182007. Accuracy: 40.\n",
      "Epoch: 22. Iteration: 486. Loss: 1.3043328523635864. Accuracy: 41.\n",
      "Epoch: 22. Iteration: 729. Loss: 1.3172820806503296. Accuracy: 40.\n",
      "Epoch: 22. Iteration: 972. Loss: 1.3961231708526611. Accuracy: 41.\n",
      "Epoch: 23. Iteration: 0. Loss: 1.3352248668670654. Accuracy: 41.\n",
      "Epoch: 23. Iteration: 243. Loss: 1.3324296474456787. Accuracy: 40.\n",
      "Epoch: 23. Iteration: 486. Loss: 1.305643081665039. Accuracy: 40.\n",
      "Epoch: 23. Iteration: 729. Loss: 1.3422088623046875. Accuracy: 40.\n",
      "Epoch: 23. Iteration: 972. Loss: 1.352001667022705. Accuracy: 41.\n",
      "Epoch: 24. Iteration: 0. Loss: 1.2708767652511597. Accuracy: 41.\n",
      "Epoch: 24. Iteration: 243. Loss: 1.3451118469238281. Accuracy: 41.\n",
      "Epoch: 24. Iteration: 486. Loss: 1.4001491069793701. Accuracy: 41.\n",
      "Epoch: 24. Iteration: 729. Loss: 1.368415117263794. Accuracy: 40.\n",
      "Epoch: 24. Iteration: 972. Loss: 1.4026482105255127. Accuracy: 41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25. Iteration: 0. Loss: 1.4077187776565552. Accuracy: 41.\n",
      "Epoch: 25. Iteration: 243. Loss: 1.3704936504364014. Accuracy: 41.\n",
      "Epoch: 25. Iteration: 486. Loss: 1.3154747486114502. Accuracy: 41.\n",
      "Epoch: 25. Iteration: 729. Loss: 1.3121947050094604. Accuracy: 41.\n",
      "Epoch: 25. Iteration: 972. Loss: 1.3786165714263916. Accuracy: 39.\n",
      "Epoch: 26. Iteration: 0. Loss: 1.3229299783706665. Accuracy: 40.\n",
      "Epoch: 26. Iteration: 243. Loss: 1.2954442501068115. Accuracy: 41.\n",
      "Epoch: 26. Iteration: 486. Loss: 1.3598051071166992. Accuracy: 41.\n",
      "Epoch: 26. Iteration: 729. Loss: 1.3671915531158447. Accuracy: 40.\n",
      "Epoch: 26. Iteration: 972. Loss: 1.3609373569488525. Accuracy: 41.\n",
      "Epoch: 27. Iteration: 0. Loss: 1.3556997776031494. Accuracy: 40.\n",
      "Epoch: 27. Iteration: 243. Loss: 1.3732348680496216. Accuracy: 40.\n",
      "Epoch: 27. Iteration: 486. Loss: 1.3496559858322144. Accuracy: 41.\n",
      "Epoch: 27. Iteration: 729. Loss: 1.318342924118042. Accuracy: 41.\n",
      "Epoch: 27. Iteration: 972. Loss: 1.370898962020874. Accuracy: 41.\n",
      "Epoch: 28. Iteration: 0. Loss: 1.3340257406234741. Accuracy: 41.\n",
      "Epoch: 28. Iteration: 243. Loss: 1.3602904081344604. Accuracy: 41.\n",
      "Epoch: 28. Iteration: 486. Loss: 1.358967661857605. Accuracy: 41.\n",
      "Epoch: 28. Iteration: 729. Loss: 1.2747746706008911. Accuracy: 41.\n",
      "Epoch: 28. Iteration: 972. Loss: 1.3786067962646484. Accuracy: 41.\n",
      "Epoch: 29. Iteration: 0. Loss: 1.3478118181228638. Accuracy: 40.\n",
      "Epoch: 29. Iteration: 243. Loss: 1.3637417554855347. Accuracy: 41.\n",
      "Epoch: 29. Iteration: 486. Loss: 1.3914252519607544. Accuracy: 41.\n",
      "Epoch: 29. Iteration: 729. Loss: 1.3657869100570679. Accuracy: 41.\n",
      "Epoch: 29. Iteration: 972. Loss: 1.3537811040878296. Accuracy: 40.\n",
      "Epoch: 30. Iteration: 0. Loss: 1.3347558975219727. Accuracy: 40.\n",
      "Epoch: 30. Iteration: 243. Loss: 1.3089172840118408. Accuracy: 40.\n",
      "Epoch: 30. Iteration: 486. Loss: 1.3750989437103271. Accuracy: 41.\n",
      "Epoch: 30. Iteration: 729. Loss: 1.3048698902130127. Accuracy: 41.\n",
      "Epoch: 30. Iteration: 972. Loss: 1.351967453956604. Accuracy: 40.\n",
      "Epoch: 31. Iteration: 0. Loss: 1.2805278301239014. Accuracy: 40.\n",
      "Epoch: 31. Iteration: 243. Loss: 1.3132580518722534. Accuracy: 41.\n",
      "Epoch: 31. Iteration: 486. Loss: 1.355525016784668. Accuracy: 40.\n",
      "Epoch: 31. Iteration: 729. Loss: 1.301011323928833. Accuracy: 41.\n",
      "Epoch: 31. Iteration: 972. Loss: 1.3817342519760132. Accuracy: 40.\n",
      "Epoch: 32. Iteration: 0. Loss: 1.3662952184677124. Accuracy: 40.\n",
      "Epoch: 32. Iteration: 243. Loss: 1.3080549240112305. Accuracy: 40.\n",
      "Epoch: 32. Iteration: 486. Loss: 1.3063844442367554. Accuracy: 42.\n",
      "Epoch: 32. Iteration: 729. Loss: 1.331419825553894. Accuracy: 40.\n",
      "Epoch: 32. Iteration: 972. Loss: 1.3562103509902954. Accuracy: 40.\n",
      "Epoch: 33. Iteration: 0. Loss: 1.3401066064834595. Accuracy: 41.\n",
      "Epoch: 33. Iteration: 243. Loss: 1.3075376749038696. Accuracy: 41.\n",
      "Epoch: 33. Iteration: 486. Loss: 1.3772056102752686. Accuracy: 41.\n",
      "Epoch: 33. Iteration: 729. Loss: 1.3330543041229248. Accuracy: 41.\n",
      "Epoch: 33. Iteration: 972. Loss: 1.3955047130584717. Accuracy: 41.\n",
      "Epoch: 34. Iteration: 0. Loss: 1.3784509897232056. Accuracy: 41.\n",
      "Epoch: 34. Iteration: 243. Loss: 1.2872081995010376. Accuracy: 40.\n",
      "Epoch: 34. Iteration: 486. Loss: 1.3695019483566284. Accuracy: 41.\n",
      "Epoch: 34. Iteration: 729. Loss: 1.2787539958953857. Accuracy: 40.\n",
      "Epoch: 34. Iteration: 972. Loss: 1.4020345211029053. Accuracy: 40.\n",
      "Epoch: 35. Iteration: 0. Loss: 1.327299952507019. Accuracy: 40.\n",
      "Epoch: 35. Iteration: 243. Loss: 1.3540087938308716. Accuracy: 40.\n",
      "Epoch: 35. Iteration: 486. Loss: 1.3425626754760742. Accuracy: 41.\n",
      "Epoch: 35. Iteration: 729. Loss: 1.327430248260498. Accuracy: 40.\n",
      "Epoch: 35. Iteration: 972. Loss: 1.326220154762268. Accuracy: 41.\n",
      "Epoch: 36. Iteration: 0. Loss: 1.3513458967208862. Accuracy: 40.\n",
      "Epoch: 36. Iteration: 243. Loss: 1.2874274253845215. Accuracy: 40.\n",
      "Epoch: 36. Iteration: 486. Loss: 1.3391330242156982. Accuracy: 41.\n",
      "Epoch: 36. Iteration: 729. Loss: 1.3389922380447388. Accuracy: 41.\n",
      "Epoch: 36. Iteration: 972. Loss: 1.359545111656189. Accuracy: 40.\n",
      "Epoch: 37. Iteration: 0. Loss: 1.3271087408065796. Accuracy: 40.\n",
      "Epoch: 37. Iteration: 243. Loss: 1.3573031425476074. Accuracy: 41.\n",
      "Epoch: 37. Iteration: 486. Loss: 1.3711875677108765. Accuracy: 40.\n",
      "Epoch: 37. Iteration: 729. Loss: 1.3573966026306152. Accuracy: 40.\n",
      "Epoch: 37. Iteration: 972. Loss: 1.265042781829834. Accuracy: 40.\n",
      "Epoch: 38. Iteration: 0. Loss: 1.419786810874939. Accuracy: 41.\n",
      "Epoch: 38. Iteration: 243. Loss: 1.3502609729766846. Accuracy: 41.\n",
      "Epoch: 38. Iteration: 486. Loss: 1.352660059928894. Accuracy: 41.\n",
      "Epoch: 38. Iteration: 729. Loss: 1.3180452585220337. Accuracy: 40.\n",
      "Epoch: 38. Iteration: 972. Loss: 1.341081142425537. Accuracy: 40.\n",
      "Epoch: 39. Iteration: 0. Loss: 1.382147192955017. Accuracy: 40.\n",
      "Epoch: 39. Iteration: 243. Loss: 1.3820064067840576. Accuracy: 40.\n",
      "Epoch: 39. Iteration: 486. Loss: 1.2898014783859253. Accuracy: 40.\n",
      "Epoch: 39. Iteration: 729. Loss: 1.2531744241714478. Accuracy: 41.\n",
      "Epoch: 39. Iteration: 972. Loss: 1.3345214128494263. Accuracy: 41.\n",
      "Epoch: 40. Iteration: 0. Loss: 1.3490712642669678. Accuracy: 41.\n",
      "Epoch: 40. Iteration: 243. Loss: 1.3959553241729736. Accuracy: 40.\n",
      "Epoch: 40. Iteration: 486. Loss: 1.408200740814209. Accuracy: 40.\n",
      "Epoch: 40. Iteration: 729. Loss: 1.3149346113204956. Accuracy: 40.\n",
      "Epoch: 40. Iteration: 972. Loss: 1.3971168994903564. Accuracy: 40.\n",
      "Epoch: 41. Iteration: 0. Loss: 1.372795581817627. Accuracy: 41.\n",
      "Epoch: 41. Iteration: 243. Loss: 1.3210035562515259. Accuracy: 40.\n",
      "Epoch: 41. Iteration: 486. Loss: 1.305594563484192. Accuracy: 40.\n",
      "Epoch: 41. Iteration: 729. Loss: 1.319627046585083. Accuracy: 40.\n",
      "Epoch: 41. Iteration: 972. Loss: 1.3410812616348267. Accuracy: 41.\n",
      "Epoch: 42. Iteration: 0. Loss: 1.36050283908844. Accuracy: 41.\n",
      "Epoch: 42. Iteration: 243. Loss: 1.4115583896636963. Accuracy: 41.\n",
      "Epoch: 42. Iteration: 486. Loss: 1.3587663173675537. Accuracy: 40.\n",
      "Epoch: 42. Iteration: 729. Loss: 1.3373076915740967. Accuracy: 41.\n",
      "Epoch: 42. Iteration: 972. Loss: 1.3203552961349487. Accuracy: 41.\n",
      "Epoch: 43. Iteration: 0. Loss: 1.3808231353759766. Accuracy: 40.\n",
      "Epoch: 43. Iteration: 243. Loss: 1.3229206800460815. Accuracy: 41.\n",
      "Epoch: 43. Iteration: 486. Loss: 1.369629979133606. Accuracy: 40.\n",
      "Epoch: 43. Iteration: 729. Loss: 1.3975533246994019. Accuracy: 41.\n",
      "Epoch: 43. Iteration: 972. Loss: 1.3274626731872559. Accuracy: 40.\n",
      "Epoch: 44. Iteration: 0. Loss: 1.331222414970398. Accuracy: 40.\n",
      "Epoch: 44. Iteration: 243. Loss: 1.3136677742004395. Accuracy: 41.\n",
      "Epoch: 44. Iteration: 486. Loss: 1.3266286849975586. Accuracy: 42.\n",
      "Epoch: 44. Iteration: 729. Loss: 1.3295714855194092. Accuracy: 41.\n",
      "Epoch: 44. Iteration: 972. Loss: 1.3487857580184937. Accuracy: 40.\n",
      "Epoch: 45. Iteration: 0. Loss: 1.3457869291305542. Accuracy: 40.\n",
      "Epoch: 45. Iteration: 243. Loss: 1.3652262687683105. Accuracy: 42.\n",
      "Epoch: 45. Iteration: 486. Loss: 1.3209363222122192. Accuracy: 42.\n",
      "Epoch: 45. Iteration: 729. Loss: 1.336356282234192. Accuracy: 41.\n",
      "Epoch: 45. Iteration: 972. Loss: 1.2928414344787598. Accuracy: 41.\n",
      "Epoch: 46. Iteration: 0. Loss: 1.3432419300079346. Accuracy: 41.\n",
      "Epoch: 46. Iteration: 243. Loss: 1.2794299125671387. Accuracy: 40.\n",
      "Epoch: 46. Iteration: 486. Loss: 1.384641408920288. Accuracy: 40.\n",
      "Epoch: 46. Iteration: 729. Loss: 1.3137627840042114. Accuracy: 41.\n",
      "Epoch: 46. Iteration: 972. Loss: 1.3829854726791382. Accuracy: 41.\n",
      "Epoch: 47. Iteration: 0. Loss: 1.3360850811004639. Accuracy: 40.\n",
      "Epoch: 47. Iteration: 243. Loss: 1.3155616521835327. Accuracy: 41.\n",
      "Epoch: 47. Iteration: 486. Loss: 1.3614847660064697. Accuracy: 40.\n",
      "Epoch: 47. Iteration: 729. Loss: 1.264245629310608. Accuracy: 40.\n",
      "Epoch: 47. Iteration: 972. Loss: 1.3194795846939087. Accuracy: 41.\n",
      "Epoch: 48. Iteration: 0. Loss: 1.3767675161361694. Accuracy: 40.\n",
      "Epoch: 48. Iteration: 243. Loss: 1.362087607383728. Accuracy: 41.\n",
      "Epoch: 48. Iteration: 486. Loss: 1.3297474384307861. Accuracy: 40.\n",
      "Epoch: 48. Iteration: 729. Loss: 1.3618273735046387. Accuracy: 40.\n",
      "Epoch: 48. Iteration: 972. Loss: 1.3342434167861938. Accuracy: 40.\n",
      "Epoch: 49. Iteration: 0. Loss: 1.283321499824524. Accuracy: 41.\n",
      "Epoch: 49. Iteration: 243. Loss: 1.366015076637268. Accuracy: 41.\n",
      "Epoch: 49. Iteration: 486. Loss: 1.4018723964691162. Accuracy: 39.\n",
      "Epoch: 49. Iteration: 729. Loss: 1.3250325918197632. Accuracy: 40.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49. Iteration: 972. Loss: 1.3058476448059082. Accuracy: 40.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "a = datetime.datetime.now().replace(microsecond=0)\n",
    "for epoch in range(epochs):\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        \n",
    "\n",
    "#         print(type(features))\n",
    "#         print(type(labels))\n",
    "        features = Variable(features)\n",
    "        labels = Variable(labels)\n",
    "#         print(type(features))\n",
    "#         print(type(labels))\n",
    "#         print(features.shape)\n",
    "#         print(labels.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features.float())\n",
    "#         print(\"output \",outputs.shape)\n",
    "#         print(\"label \",labels.shape)\n",
    "#         print(\"output \",outputs[0])\n",
    "#         print(\"label \",labels[0])\n",
    "        loss = criterion(outputs.float(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        if i % (len(X_train)// (4 * batch_size))  == 0:\n",
    "            # calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for features, labels in val_loader:\n",
    "                features = Variable(features)\n",
    "                outputs = model(features.float())\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total+= labels.size(0)\n",
    "                # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
    "                correct+= (predicted == labels).sum()\n",
    "            accuracy = 100 * correct/total\n",
    "            if(epoch % 5 == 0 and i == 0):\n",
    "                print(\"Epoch: {}. Iteration: {}. Loss: {}. Accuracy: {}.\".format(epoch, i, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:09:39\n"
     ]
    }
   ],
   "source": [
    "b = datetime.datetime.now().replace(microsecond=0)\n",
    "print(b-a)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}